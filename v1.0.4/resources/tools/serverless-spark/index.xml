<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Serverless for Apache Spark on MCP Toolbox for Databases</title><link>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/</link><description>Recent content in Serverless for Apache Spark on MCP Toolbox for Databases</description><generator>Hugo</generator><language>en</language><atom:link href="https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/index.xml" rel="self" type="application/rss+xml"/><item><title>serverless-spark-get-batch</title><link>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-get-batch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-get-batch/</guid><description>&lt;h1 id="serverless-spark-get-batch">serverless-spark-get-batch&lt;/h1>
&lt;p>The &lt;code>serverless-spark-get-batch&lt;/code> tool allows you to retrieve a specific
Serverless Spark batch job. It&amp;rsquo;s compatible with the following sources:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://xgs925.github.io/genai-toolbox/v1.0.4/resources/sources/serverless-spark/">serverless-spark&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;code>serverless-spark-list-batches&lt;/code> accepts the following parameters:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;code>name&lt;/code>&lt;/strong>: The short name of the batch, e.g. for
&lt;code>projects/my-project/locations/us-central1/my-batch&lt;/code>, pass &lt;code>my-batch&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>The tool gets the &lt;code>project&lt;/code> and &lt;code>location&lt;/code> from the source configuration.&lt;/p>
&lt;h2 id="example">Example&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">tools&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">get_my_batch&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">serverless-spark-get-batch&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">source&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">my-serverless-spark-source&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Use this tool to get a serverless spark batch.&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="response-format">Response Format&lt;/h2>
&lt;p>The response contains the full Batch object as defined in the &lt;a href="https://cloud.google.com/dataproc-serverless/docs/reference/rest/v1/projects.locations.batches#Batch">API
spec&lt;/a>,
plus additional fields &lt;code>consoleUrl&lt;/code> and &lt;code>logsUrl&lt;/code> where a human can go for more
detailed information.&lt;/p></description></item><item><title>serverless-spark-list-batches</title><link>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-list-batches/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-list-batches/</guid><description>&lt;h2 id="about">About&lt;/h2>
&lt;p>A &lt;code>serverless-spark-list-batches&lt;/code> tool returns a list of Spark batches from a
Google Cloud Serverless for Apache Spark source. It&amp;rsquo;s compatible with the
following sources:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://xgs925.github.io/genai-toolbox/v1.0.4/resources/sources/serverless-spark/">serverless-spark&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;code>serverless-spark-list-batches&lt;/code> accepts the following parameters:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;code>filter&lt;/code>&lt;/strong> (optional): A filter expression to limit the batches returned.
Filters are case sensitive and may contain multiple clauses combined with
logical operators (AND/OR). Supported fields are &lt;code>batch_id&lt;/code>, &lt;code>batch_uuid&lt;/code>,
&lt;code>state&lt;/code>, &lt;code>create_time&lt;/code>, and &lt;code>labels&lt;/code>. For example: &lt;code>state = RUNNING AND create_time &amp;lt; &amp;quot;2023-01-01T00:00:00Z&amp;quot;&lt;/code>.&lt;/li>
&lt;li>&lt;strong>&lt;code>pageSize&lt;/code>&lt;/strong> (optional): The maximum number of batches to return in a single
page.&lt;/li>
&lt;li>&lt;strong>&lt;code>pageToken&lt;/code>&lt;/strong> (optional): A page token, received from a previous call, to
retrieve the next page of results.&lt;/li>
&lt;/ul>
&lt;p>The tool gets the &lt;code>project&lt;/code> and &lt;code>location&lt;/code> from the source configuration.&lt;/p></description></item><item><title>serverless-spark-cancel-batch</title><link>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-cancel-batch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-cancel-batch/</guid><description>&lt;h2 id="about">About&lt;/h2>
&lt;p>&lt;code>serverless-spark-cancel-batch&lt;/code> tool cancels a running Spark batch operation in
a Google Cloud Serverless for Apache Spark source. The cancellation request is
asynchronous, so the batch state will not change immediately after the tool
returns; it can take a minute or so for the cancellation to be reflected.&lt;/p>
&lt;p>It&amp;rsquo;s compatible with the following sources:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://xgs925.github.io/genai-toolbox/v1.0.4/resources/sources/serverless-spark/">serverless-spark&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;code>serverless-spark-cancel-batch&lt;/code> accepts the following parameters:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;code>operation&lt;/code>&lt;/strong> (required): The name of the operation to cancel. For example,
for &lt;code>projects/my-project/locations/us-central1/operations/my-operation&lt;/code>, you
would pass &lt;code>my-operation&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>The tool inherits the &lt;code>project&lt;/code> and &lt;code>location&lt;/code> from the source configuration.&lt;/p></description></item><item><title>serverless-spark-create-pyspark-batch</title><link>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-create-pyspark-batch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-create-pyspark-batch/</guid><description>&lt;h2 id="about">About&lt;/h2>
&lt;p>A &lt;code>serverless-spark-create-pyspark-batch&lt;/code> tool submits a Spark batch to a Google
Cloud Serverless for Apache Spark source. The workload executes asynchronously
and takes around a minute to begin executing; status can be polled using the
&lt;a href="https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-get-batch/">get batch&lt;/a> tool.&lt;/p>
&lt;p>It&amp;rsquo;s compatible with the following sources:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://xgs925.github.io/genai-toolbox/v1.0.4/resources/sources/serverless-spark/">serverless-spark&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;code>serverless-spark-create-pyspark-batch&lt;/code> accepts the following parameters:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;code>mainFile&lt;/code>&lt;/strong>: The path to the main Python file, as a gs://&amp;hellip; URI.&lt;/li>
&lt;li>&lt;strong>&lt;code>args&lt;/code>&lt;/strong> Optional. A list of arguments passed to the main file.&lt;/li>
&lt;li>&lt;strong>&lt;code>version&lt;/code>&lt;/strong> Optional. The Serverless &lt;a href="https://docs.cloud.google.com/dataproc-serverless/docs/concepts/versions/dataproc-serverless-versions">runtime
version&lt;/a>
to execute with.&lt;/li>
&lt;/ul>
&lt;h2 id="custom-configuration">Custom Configuration&lt;/h2>
&lt;p>This tool supports custom
&lt;a href="https://docs.cloud.google.com/dataproc-serverless/docs/reference/rest/v1/RuntimeConfig">&lt;code>runtimeConfig&lt;/code>&lt;/a>
and
&lt;a href="https://docs.cloud.google.com/dataproc-serverless/docs/reference/rest/v1/EnvironmentConfig">&lt;code>environmentConfig&lt;/code>&lt;/a>
settings, which can be specified in a &lt;code>tools.yaml&lt;/code> file. These configurations
are parsed as YAML and passed to the Dataproc API.&lt;/p></description></item><item><title>serverless-spark-create-spark-batch</title><link>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-create-spark-batch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-create-spark-batch/</guid><description>&lt;h2 id="about">About&lt;/h2>
&lt;p>A &lt;code>serverless-spark-create-spark-batch&lt;/code> tool submits a Java Spark batch to a
Google Cloud Serverless for Apache Spark source. The workload executes
asynchronously and takes around a minute to begin executing; status can be
polled using the &lt;a href="https://xgs925.github.io/genai-toolbox/v1.0.4/resources/tools/serverless-spark/serverless-spark-get-batch/">get batch&lt;/a> tool.&lt;/p>
&lt;p>It&amp;rsquo;s compatible with the following sources:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://xgs925.github.io/genai-toolbox/v1.0.4/resources/sources/serverless-spark/">serverless-spark&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;code>serverless-spark-create-spark-batch&lt;/code> accepts the following parameters:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;code>mainJarFile&lt;/code>&lt;/strong>: Optional. The gs:// URI of the jar file that contains the
main class. Exactly one of mainJarFile or mainClass must be specified.&lt;/li>
&lt;li>&lt;strong>&lt;code>mainClass&lt;/code>&lt;/strong>: Optional. The name of the driver&amp;rsquo;s main class. Exactly one of
mainJarFile or mainClass must be specified.&lt;/li>
&lt;li>&lt;strong>&lt;code>jarFiles&lt;/code>&lt;/strong>: Optional. A list of gs:// URIs of jar files to add to the CLASSPATHs of
the Spark driver and tasks.&lt;/li>
&lt;li>&lt;strong>&lt;code>args&lt;/code>&lt;/strong> Optional. A list of arguments passed to the driver.&lt;/li>
&lt;li>&lt;strong>&lt;code>version&lt;/code>&lt;/strong> Optional. The Serverless &lt;a href="https://docs.cloud.google.com/dataproc-serverless/docs/concepts/versions/dataproc-serverless-versions">runtime
version&lt;/a>
to execute with.&lt;/li>
&lt;/ul>
&lt;h2 id="custom-configuration">Custom Configuration&lt;/h2>
&lt;p>This tool supports custom
&lt;a href="https://docs.cloud.google.com/dataproc-serverless/docs/reference/rest/v1/RuntimeConfig">&lt;code>runtimeConfig&lt;/code>&lt;/a>
and
&lt;a href="https://docs.cloud.google.com/dataproc-serverless/docs/reference/rest/v1/EnvironmentConfig">&lt;code>environmentConfig&lt;/code>&lt;/a>
settings, which can be specified in a &lt;code>tools.yaml&lt;/code> file. These configurations
are parsed as YAML and passed to the Dataproc API.&lt;/p></description></item></channel></rss>